---
layout: post
title: MADHAV Lab Tic (MTic) Database.
permalink: /datasets/m3/
---

## Global information

We evaluate the proposed method on a variety of datasets - including both real recordings as well as synthetically generated audio.  
We prepare a new dataset, called MTic. A reference audio signal of periodic tics with a time period of $1$s is played on a phone speaker and is recorded by the microphone of the same phone.
Tics are chosen for experiments because they are localized in time and are musically relevant (as in metronome). The recordings are done with a number of phones and in a variety of acoustic background conditions.
The time delay in the recorded signal is $<0.9$s.
There are total 170 audio recordings sampled at \(16kHz\), each of a duration of almost \(10\) seconds. They all correspond to the same reference audio of $10$s duration.
Furthermore, to increase the sample size, we synthetically generate 450 audio files from the same reference signal with delays chosen uniformly between \((0s,0.9s]\) and noise injections with signal-to-noise ratio varying in \([0dB,30dB]\). 

To validate the robustness of this study over real world signals such as speech and music as well, we experiment with speech files from the LibriSpeech dataset \cite{ref22} which contains speech recordings from read audiobooks in English, sampled at 16kHz; speech is non periodic. We sampled 10000 speech audio files and 80:20 split on top of these files was used for training and validation. For each epoch, a noisy and delayed signal was synthesized with an SNR in \([0dB,30dB]\) and delayed by an amount in \((0.2s,3s]\) from each recording in the training set. Therefore, the network was trained of different reference-delayed pair, sampled from the same process.
We also experiment with the accompaniment music from MIREX 2012 dataset \cite{ref23}, which we call MBeats dataset. 
The MTic dataset as well as the codes to reproduce the results in this paper are available at
\texttt{https://github.com/madhavlab/2022\_syncnet}.




  - Download link: <https://sigmedia.tcd.ie/>
  - Contact: [sigmedia_database@tcd.ie](mailto:sigmediag_database@tcd.ie) - The subject **must start** with the tag [RoomReader Corpus Question] (If the tag is not provided or invalid, your email will be ignored)
  - License:
  - Reference:

```bibtex
@inproceedings{reverdy2021,
    title = "{R}oomReader: A Multimodal Corpus of Online Multiparty Conversational Interactions",
    author = "Reverdy, Justine  and
      O'Connor Russell, Sam  and
      Duquenne, Louise  and
      Garaialde, Diego  and
      Cowan, Benjamin  and
      Harte, Naomi",
    booktitle = "Proceedings of the Thirteenth International Conference on Language Resources and Evaluation ({LREC}{'}21)",
    month = june,
    year = "2021",
    address = "Marseille, France",
    publisher = "European Language Resources Association (ELRA)",
    url = "https://lrec2022.lrec-conf.org/en/conference-programme/accepted-papers/",
}
```

## Description

RoomReader is a corpus of multimodal, multiparty conversational interactions in which participants followed a collaborative student-tutor scenario designed to elicit spontaneous speech. The corpus was developed within the wider RoomReader Project to explore multimodal cues of conversational engagement and behavioural aspects of collaborative interaction in online environments. However, the corpus can be used to study a wide range of phenomena in online multimodal interaction. The corpus consists of over 8 hours of video and audio recordings from 118 participants in 30 gender-balanced sessions, in the “in-the-wild” online environment of Zoom. The recordings have been edited, synchronised, and fully transcribed. Student participants have been continuously annotated for engagement with a novel continuous scale. We provide questionnaires measuring engagement and group cohesion collected from the annotators, tutors, and participants themselves. We also make a range of accompanying data available such as personality tests and behavioural assessments. The dataset and accompanying psychometrics present a rich resource enabling the exploration of a range of downstream tasks across diverse fields including linguistics and artificial intelligence.
